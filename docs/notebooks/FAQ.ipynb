{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbdf1a03-663c-495d-b11e-0e08c4839de5",
   "metadata": {},
   "source": [
    "# FAQ\n",
    "\n",
    "Here are some common questions and answers. If you can't find what you're looking for here, please file an issue on our [GitHub page](https://github.com/sagar87/spatialproteomics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8155a8-5e86-4c83-97a2-4425dcf0f621",
   "metadata": {},
   "source": [
    "## How can I optimize my memory usage?\n",
    "\n",
    "Running out of memory is a common problem when dealing with large images. Here are a couple of things you could consider to make your workflow more memory efficient.\n",
    "\n",
    "- **Lazy loading with zarr:** if you already have your objects stored in `zarr` format, it is more memory-efficient to load them using `xr.open_zarr(file)` than `xr.load_dataset(file)`.\n",
    "- **Subsetting:** if you already know that you will require only a subset of your data, e. g. looking at certain channels, it is advised to perform subsetting as early as possible. This can be done with `ds.pp[channels]`.\n",
    "- **Deleting objects which are not required anymore:** spatialproteomics deliberately does not perform in-place operations, but rather copies the existing object to return a new one. This can be heavy on memory, if you do not remove intermediate variables once you do not need them anymore. You could consider removing them with `del` like this:\n",
    "```\n",
    "ds_new = ds.pp.your_workflow()\n",
    "del ds\n",
    "```\n",
    "- **Downsampling:** when looking at large images, you can downsample the image before plotting using `ds.pp.downsample(rate=8)`. When zooming into a specific area, you can omit the downsampling again.\n",
    "- **Garbage collection:** this is especially relevant if you perform operations in a for loop. If you try to store the dataset in the same variable, python's garbage collection might have some troubles freeing up memory due to cyclical references (for more information, please refer to [this post](https://dev.to/karishmashukla/how-python-uses-garbage-collection-for-efficient-memory-management-270h)). In this case, calling the garbage collector manually can help alleviate some of those issues:\n",
    "```\n",
    "import gc\n",
    "for ds in [...]:\n",
    "    ds = ds.pp.your_workflow()\n",
    "    gc.collect()  # manually calling the garbage collector after each iteration\n",
    "```\n",
    "\n",
    "## I have a lot of samples. Can I use parallelization to speed up the analysis?\n",
    "Yes, this is exactly what `dask` is useful for. Their [documentation](https://examples.dask.org/applications/embarrassingly-parallel.html) provides a good starting point for this. Since `spatialproteomics` is built on top of `xarray`, parallelization with `dask` is natively supported. If you want to apply the same workflow to a bunch of files, you could do it like this:\n",
    "```\n",
    "from dask import delayed, compute\n",
    "\n",
    "def process_file(path):\n",
    "    import spatialproteomics as sp  \n",
    "    ds = (xr.open_zarr(path)\n",
    "          .pp.add_quantification(func=\"intensity_mean\")\n",
    "          .pp.transform_expression_matrix(method=\"arcsinh\"))\n",
    "    return ds\n",
    "    \n",
    "tasks = [delayed(process_file)(f) for f in files]\n",
    "results = compute(*tasks, scheduler=\"processes\", num_workers=16)\n",
    "```\n",
    "\n",
    "This can result in substantial speedup compared to sequential execution with for loops, as illustrated below.\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "    <img src=\"../_static/img/dask_parallelization.png\" alt=\"Dask enables the parallelization of workflows, substantially speeding up execution times.\" style=\"width:50%;\"/>\n",
    "</p>\n",
    "\n",
    "## When do I apply method directly on the object, and when do use sp.method()?\n",
    "\n",
    "Spatialproteomics has two distinct backends: a `xarray` backend and a `spatialdata` backend. These follow slightly different philosophies.\n",
    "\n",
    "The `xarray` backend is based on a functional programming design. This means that you can use it to call methods directly on your object, allowing you to pipe data from one step to the next. For example, this could look like `my_data.pp.segment().la.predict_cell_types().pl.show()`. Internally, `spatialproteomics` takes care of synchronizing shared dimensions across your data.\n",
    "\n",
    "The `spatialdata` backend is for when you want to use `spatialdata` objects from the start. In this case, the syntax is slightly different, but more similar to syntax you might be used to from scverse packages (such as scanpy or squidpy). Here, your code would look like this:\n",
    "```\n",
    "import spatialproteomics as sp\n",
    "sp.pp.segment(my_data)\n",
    "sp.pp.predict_cell_types(my_data)\n",
    "```\n",
    "These operations modify your object in-place, unless you set `copy=True` in the method signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485d761-8781-41e2-bac8-33d1b3bf0e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp_env_2",
   "language": "python",
   "name": "tmp_env_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
